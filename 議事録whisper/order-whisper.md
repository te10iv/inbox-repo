
# cursolへの依頼
以下の
インプット情報①
と
インプット情報②
をもとに、
how-to-use-whisper.mdを作って、内容記載して。

▼含めてほしい情報
# 検討（外部に情報もらさずローカルでできるもの）
# なぜwhishperが良いか
# whishper使うにしても、注意点あり
## 導入手順　※注意すべき機能や手順は大文字や赤字にする





# 以下はインプット情報①とインプット情報②です
## インプット情報①　参考動画

【音声文字起こし5】超高精度！音声認識AI WhisperをローカルインストールしてPythonで使ってみる！～インストール～GPU利用、実践プ
https://www.youtube.com/watch?v=Yv75_hU0hdg




▼文字起こし

動画の関連情報



チャプター

文字起こし

 オープニング
以前の動画でChatGPTで有名なOpenAI社の
Whisperを使って、録音した音声ファイルを
文字起こしするPythonプログラムを作成しました。
ただし、その際利用したWhisperは、OpenAIのWhisperを API利用して、音声を 文字起こししていました。
API利用は1分約0.9円と非常に安いものの、 ユーザー登録やクレジットカードの登録など、
個人で利用するには、若干、ハードルが高いです。
さらに、API利用するということは、一時的に、インターネットを 介して、OpenAI社のクラウド環境に音声データが
送られることになる為、情報漏洩の観点で、クラウド利用が 厳しい会社にとっても、ハードルがありました。
一方、OpenAIのWhisperは実は、オープンソース として公開されているのです。
つまり、自分のパソコンにインストールして Pythonなどから無料で使うことが出来ます。
そこで、今回は、音声文字起こしのWhisperを、 パソコンにローカルインストールして、Pythonから、
無料で、安心して使えるプログラムを 作成していきたいと思います。
さらに、私は、これまで様々な音声文字変換
アプリを試して変換精度を確認してきました。
そこで、Whisperのローカル版の変換精度も、
これまで試した音声文字変換アプリの精度と
比較したいと思います。
 利用環境紹介
まず、今回使う、環境をご紹介します。
まず、ハードウェアとしては、私のパソコンは自作のゲーミングPCでメモリー32Gバイト、
CPUはIntel Corei5 6コアです。
また、グラフィックボード GPUとして、NVIDIAのGeforce GTX1650 4Gモデルを搭載しています。
Whisperをローカルで動かすには、GPUが有った方が速いようですので、最終的にはGPUも使えるように
セットアップしていきたいと思います。
また、Pythonの開発環境としては、VSCodeを使います。
Pythonのバージョンはいくつかあるのですが、今回は3.10.0を使いたいと思います。
また、Whisperを使う環境は普段使っている環境と独立して動かしたいので、VENVで仮想環境を作って
セットアップしていきたいと思います。
Whisperを使うには、その他のライブラリーとして、PyTorchなど、いくつかセットでインストールされる
ライブラリーがあるのですが、バージョンの関係がシビアなようですので、他のプログラムの影響を避けるためにも、
独立した仮想環境でインストールすることをお勧めします。
では、早速、始めたいと思います。
 仮想環境構築
まず、VENVで今回の環境を作っていきます。
Whisper専用の環境として、まずは適当なフォルダを作成します。
例えば、Gドライブの直下に、050_VENVというフォルダを作成し、さらに、010_Whisperというフォルダを作成します。
そして、VSCodeのコマンドラインから、環境を作っていきます。
まず、現在のPythonのバージョンを確認します。
このようにバージョンが3.10.0になっていることが分かります。
そして、CDコマンドで先ほど作成したフォルダにチェンジディレクトリします。
そして、この状態で、python -m venv whisperと入力し、実行します。
しばらくすると、コマンドプロンプトに戻り、仮想環境が出来上がります。
このように、先ほど作成したフォルダの中に、whisperというフォルダが出来上がります。
環境が出来上がりましたので、仮想環境を立ち上げたいと思います。
コマンドプロンプトから ドット.\ whisper\Scripts\activate と入力して、実行します。
すると、コマンドプロンプトの前方に、(whisper)という文字が付いて、先ほど作成した
仮想環境に入ったことが分かります。
python -Vでpythonのバージョンを確認すると、3.10.0になっていることが分かります。
また、pip listでインストールされているライブラリーを確認すると、ほとんど何も入っていない
新しい環境であることが分かります。
また、初めての環境ですので、このようにpipが古いので、
バージョンアップを促すメッセージが表示されます。
pip install --upgrade pipで pipをバージョンアップしておきます。
このように、venvを使って、簡単に独立した環境が作成できました。
では、ここからは、whisperを セットアップしていきたいと思います。
 Whisperインストール
whisperのセットアップ方法や使い方は、githubのOpenAIのwhisperのページに掲載されています。
そのページを見ていくと、whisperの仕組みなども記載されていますが、難しそうで良く分かりませんが、
さらに下に、セットアップ方法が記載されています。
そこには、pythonのバージョンは3.9.9で確認済みですが、3.8から3.11で動くと思われる旨が記載されていますので、
今回の環境の3.10.0でセットアップしてみます。
インストールコマンドとしては、ここに掲載されているpipコマンドでセットアップしていきます。
コマンドプロンプトから pip install -U OpenAI-whisperでインストールします。
すると、関連する、他のライブラリーも一緒にインストールされるようです。
そして、このようにインストールが完了しました。
そして、インストール後の状態をpip listで確認します。
すると、このように、OpenAI-whisperの他に、PyTorch
など様々なライブラリーが同時にインストールされました。
これらのライブラリーの依存関係が結構シビアで、このバージョンでハマるケースが多いので、whisperを
セットアップするにあたっては、venvなどによる仮想環境で
新規の専用環境を構築した方が良いです。
 プログラム開発～テスト実行
では、簡単なプログラムで、whisperを動かしてみたいと思います。
サンプルプログラムは、先ほどのgithubのページに掲載されていますので、それを動かして見たいと思います。
プログラムをコピーして、適当な名前で保存します。
ここでのポイントとして、whisperには、すでに各言語を学習した学習済みファイルがあるのですが、
実行環境のメモリーなどの環境に応じて、モデルの大きさが選択できるようになっています。
このように、tinyからlargeまであり、大きくなれば変換精度が上がる一方で、
必要なメモリーが増えると共に、 処理にかかる時間が長くなります。
まずは、baseで実行してみたいと思います。
音声ファイルを準備し、そのファイルをインプットに、プログラムを実行します。
途中、警告メッセージが出ましたが、処理は実行中です。
すると、このように、音声ファイルに含まれる、
言葉が、文字変換されました。
今回のファイルは、私のYoutubeの冒頭の
「皆さん、こんにちは。大福ちゃんねるです！」の
挨拶音声でしたので、正しく文字起こし出来ました。
 GPU認識
先ほど、実行した際、このように、
警告メッセージが出ていました。
これは、CPUで実行する場合、FP16は
サポートしていないと言っています。
警告メッセージですので、このままでも使えるのですが、私の場合、NVIDIAのGPUが有りますので、
GPUで使えるようにしていきたいと思います。
GPUを使うには、CUDAのインストールと、GPUに対応したPyTorchをインストールする必要があります。
まず、CUDAをインストールします。
CUDAはNVIDIAのホームページからダウンロードします。
このように、多くのバージョンがあります。
どのバージョンをインストールするかは、事前にPyTorchのバージョンと組み合わせる必要があります。
PyTorchのホームページによると、このように、最新のPyTorchの場合、windowsでpythonで使う場合、
CUDAのバージョンは11.7か11.8が良さそうです。
そこで、CUDAのホームページから、11.7.0のCUDAをダウンロードします。
リンクをクリックすると、このようにインストールする環境を選択する画面が表示されます。
私の場合、Windowsでバージョン10になります。
そして、ローカルインストールのファイルを選択します。
すると、2.5Gバイトのファイルを ダウンロードすることになります。
そして、ダウンロードが完了すると、このように、インストールファイルがダウンロードされますので、
このファイルを実行してインストールをします。
基本的には、デフォルトで進んでいきます。
インストールの最後に、ショートカットの配置や起動をするかのチェックが有りますが、
今回はPythonプログラムから使いたいだけですので、チェックは不要です。
これで、CUDAのインストールは完了です。
続いて、GPUに対応したPyTorchを インストールしていきます。
ただし、その前に、先ほどインストールしたCPU版の
PyTorchをアンインストールする必要があります。
pip uninstall torchでアンインストールします。
GPUに対応したPyTorchをインストールするには、PyTorchのホームページから、バージョンを選択すると、
一番下に、pipのインストールコマンドが表示されますので、それをコピーして実行します。
処理を実行すると、このように、インストールが実行されます。
しばらくすると、インストールが完了します。
pip listでインストール結果を確認します。
すると、このように、PyTorchの2.0.1の
cuda11.7がインストールされました。
ちゃんとGPUが認識できているか確認する為、このようなプログラムを実行してみます。
すると、このように、GPUが認識できていることがわかりました。
これで、PyTorchのGPUバージョンのセットアップが完了です。
そして、先ほどのWhisperのプログラムを実行してみます。
すると、このように、先ほどCPUで実行した際の
警告メッセージが表示されなくなりました。
 モデル毎の変換精度比較
ここからは、Whisperの各モデル別に、変換精度を見ていきたいと思います。
Whisperのモデルはこのようにtinyからlargeまで、5種類のモデルがありますので、まずはtinyで試してみます。
変換精度の比較は、私の動画で良く登場している、菅総理が、2021年に新型コロナウィルスの際、
緊急事態宣言を発表した記者会見の 約2分30秒の音声を変換します。
また、それぞれの変換時間も同時に計測する為、処理の最初と最後に時間をprintするようにしたいと思います。
まず、tinyで実行します。
すると、このように、処理が完了しました。
処理時間は、約11秒でした。
では、変換精度を見ていきます。
すると、このように、あまり精度は高く無いです。
同音異義語の間違いも含めると、538文字中106文字の間違いで、変換精度は80.3%となりました。
続いて、baseのモデルで処理をしてみたいと思います。
すると、処理時間は15秒でした。
また、変換精度は、45文字間違いの　90.6%でした。
かなり良くなりました。
続いて、smallで試してみます。
すると、処理時間は32秒でした。
また、変換精度は、22文字間違いの95.7%でした。
２分30秒の音声ファイルが32秒で変換出来ていますので、十分　利用可能です。
また、変換精度95.7%は、これまで私が実験してきた中の、GoogleDocumentや　UDトークの変換エンジンの
AmiVoiceと同等ですので、かなりの変換精度です。
続いて、mediumで試してみます。
すると、処理時間は一気に伸びて、３分9秒でした。
2分30秒の音声ファイルの変換に3分以上かかっていますので、これではリアルタイムの音声変換には使えないことになります。
ただ、モデルの表を見ると、必要なVRAMの スペックが5Gバイトとなっています。
私の使っているパソコンのGPUはNVIDIA GTX1650でVRAMは4Gバイトしかないので、スペック不足の可能性が高いです。
おそらく、もう少しハイスペックのGPUを使えば、もっと早く、処理が完了すると思います。
一方で、変換精度は11文字間違いの 97.9%と非常に精度が上がってきました。
最後に、largeを試してみます。
すると、処理時間はさらに伸びて、6分53秒かかりました。
一方で、変換精度は、わずか2文字間違いの 99.6%となり、ほぼ完璧な変換になりました。
 変換精度まとめ
この変換精度をまとめると、このようになります。
そして、この変換精度を、これまで私が試してきた
ツールと比較すると、このようになります。
Whisper Local版のlargeの変換精度は、処理時間が
かかるものの、API版より、さらに精度が良かったです。
参考に、私のパソコンで、GPUで処理した際とCPUで処理した際の処理速度の違いを見てみましたので、
ご紹介したいと思います。
このように、tiny、base、smallはGPUで処理した方が速かったのに対して、なんと、mediumとlargeは
逆にCPUで処理をした方が速く終わりました。
そこで、処理中のパフォーマンスモニターで確認したところ、GPU処理中のパフォーマンスモニターを見ると、
GPUを使い切る前に、GPUのメモリーの4Gバイトを使い切っています。
メモリーが頭打ちになり、せっかくの GPUが使い切れていないようです。
それに対して、CPU処理のパフォーマンスモニターを見ると、メモリーは32Gバイト中の16Gバイトしか使っておらず、
CPUをフル活用しています。
つまり、Whisperの高精度モデルを使う場合、GPUよりメモリーの方が重要であることが分かりました。
おそらく、GPUでも、NVIDIAのRTX 3060などの12Gバイトのメモリーが搭載されたモデルを使うと、
もっと処理が早くなると思われます。
 実践プログラム紹介
ここまで、Whisperのモデル毎の精度と、処理速度を見てきましたが、最後に、音声ファイルを選択して、
音声を文字起こしするアプリを作って行きたいと思います。
以前の動画で、WhisperのAPIを使って、音声ファイルを文字起こしするアプリを作成しましたので、
そのプログラムを改造して、ローカル版のWhisperを使って文字起こしするプログラムにしたいと思います。
このように、最初に音声ファイルを選択して、１分毎に分割し、その音声ファイルをWhisperのローカル版で
文字起こしします。
また、結果をエクセルに保存すると共に、分割した音声ファイルへのリンクを貼るようにします。
そして、作成したプログラムがこちらです。
100行以下の短いプログラムですが、音声ファイルとしてはwavやmp3、m4aやmp4形式にも対応しています。
そして、1分毎のファイルに分割するようにしています。
また、今回は、mediumのモデルを使いたいと思います。
では、実際に実行してみたいと思います。
 プログラム実行
処理を実行すると、ファイルを選択するポップアップが表示されます。
そして、音声ファイルを選択すると、 1分毎に変換処理が始まります。
処理が完了すると、output_folderに 分割された音声ファイルが保存されます。
また、音声ファイルと同じフォルダに、エクセルファイルが保存され、そのファイルを開くと、このように、
文字起こし結果が出力されています。
さらに、音声ファイルへのリンクが付いていますので、音声を聞きながら、変換結果を確認することが出来ます。
 エンディング
以上、今回は、無料で使える音声文字起こしのWhisperをローカルインストールして、
音声文字起こしアプリを作成しました。
無料なのに、超高精度なモデルも使えて、業務にも、そのまま使えるのではないかと思いますので、
皆さんも一度チャレンジしてみては如何でしょうか
尚、今回作成したプログラムは、エンジニア向けの情報共有サイトのQiitaでも公開しており、
動画の概要欄にリンクを付けていますので、もしよかったら、ご覧ください。
最後まで、ご視聴、ありがとうございました。

## インプット情報②　▼chatgptとのやりとり

会社の議事録音声を、絶対に情報漏洩させずにテキスト化できる無料のAIツールある？

結論から言うと、**機密性の高い会議の音声を「絶対に情報漏洩させずに」無料でAI文字起こしするには、クラウド型の無料サービスは避けて、ローカル（自分の PC/スマホ内）で処理する方法が最も安全です。**多くの無料文字起こしサービスはクラウドに音声をアップロードする仕様のため、機密情報の扱いとして不十分なことが多いです。
AI経営総合研究所
+1

以下に「情報漏洩リスクを極力排除できる選択肢」を紹介します：

1. ローカルで処理する無料／オープンソース文字起こし

ポイント: 自分の端末（PC/サーバー）上で処理するため、インターネットに音声データを送信しません。機密情報の漏洩リスクを大幅に減らせます。

(A) OpenAI Whisper（オープンソース）

概要: OpenAI が無償で公開している音声認識モデルで、自分の PC 上で動かせます。

安全性: 音声ファイルは自分のマシン内で完結して処理されるため、クラウドへの送信がありません。
ウィキペディア

料金: 完全無料（オープンソースモデル）。

難易度: 初期セットアップ（Python 環境）が必要です。

Whisper を使うには Python などの環境構築が必要ですが、オンプレミスで処理を完結できるため内部情報保護ができます。
ウィキペディア

(B) オフライン文字起こしツール（ローカル処理）

これらはインターネットに接続せず、端末内だけで文字起こし可能です。

WizWhisp（Windows 向け MS ストアアプリ）
→ 完全オフラインで文字起こし可能、データが外部サーバに送信されません。
マイクロソフトストア

Offline Transcription アプリ（Mac/PC）
→ データが端末内に留まる仕様。
App Store

oTranscribe（ブラウザベースだがローカル保存）
→ ブラウザ上で音声と文字を操作し、音声や文字データはローカルに保存されます。クラウドには送信されません。
otranscribe.com

自己ホスト型プロジェクト（GitHub など）
→ 「vibe」や「Scriberr」など、自分でセットアップして完全ローカル処理可能なオープンソースもあります。
GitHub
+1

これらはすべてクラウドを介さずに処理できるため、音声データや文字起こし結果が外部に出ません。

2. クラウド型無料サービスは企業機密には不向き

無料のクラウド型 AI 文字起こしサービス（Otter.ai や Speechnotes など）は便利ですが、データが外部サーバーにアップロードされ、利用規約によっては学習に使われる可能性もあります。そのため機密性の高い内容の議事録には向きません。
ウィキペディア
+1

運用上の注意（企業での安全対策）

音声ファイルを暗号化して保存
会議録音ファイル自体も機密性が高いため、暗号化して保管しましょう。

ローカルネットワーク・端末のセキュリティ強化
オフラインでも端末自体が攻撃を受ける可能性を考慮し、OS のアップデートやウイルス対策を必ず行います。

社内ポリシーの策定
機密会議の文字起こしを行う際の承認手順・保存期限・アクセス制限などルール化します。
サイバーセキュリティ.com

まとめ（用途別おすすめ）
利用形態	おすすめ手段	情報漏洩リスク
機密性最重視（社内会議）	Whisper または完全オフラインツール	最小（クラウド送信なし）
手軽さ重視（非機密）	オンライン無料サービス	中程度（アップロードあり）
自動化・要約付き	オンプレミスの導入ツール	条件次第で安全

必要なら、Whisper やオフラインツールを実際にどうインストールして使うか（Windows / macOS それぞれの具体的な手順）をステップバイステップで案内できます。希望があれば教えてください。

googleドキュメントで文字起こしできると聞いたが、どうやるの？
googleに情報を持っていかれる？

以下、手順と**情報漏洩リスク（Googleに持っていかれるか）**を分けて、正確に説明します。

1. Googleドキュメントで文字起こしする方法（公式機能）

Googleドキュメントには 「音声入力（Voice Typing）」 という標準機能があります。
※これは「音声ファイルをアップロードして文字起こし」ではなく、マイク入力をリアルタイムで文字起こしする方式です。

手順（PCのみ対応）

Google Chromeで Googleドキュメントを開く
※音声入力は Chrome 必須

メニューから
［ツール］→［音声入力］

マイクのアイコンが表示される

マイクをクリックして録音開始

会議音声を

マイクでそのまま拾う

もしくはPCで再生した音声をマイクに流す

話された内容がリアルタイムでテキスト化される

補足：

日本語対応あり

無料

精度は比較的高い（Google Speech APIベース）

2. 既存の音声ファイルは直接アップロードできる？

できません。

Googleドキュメント単体では
❌ 音声ファイル（mp3 / wav 等）を直接読み込んで文字起こし
は不可です。

そのため実務では、以下のような“疑似文字起こし”をします。

疑似文字起こしの例

会議録音（wav/mp3）をPCで再生

Googleドキュメントの音声入力をON

スピーカー or 仮想オーディオデバイス経由でマイク入力

※ この方法でも Google側には音声が送信されます

3. 一番重要：Googleに情報は持っていかれる？
結論

YES。Googleに音声データは送信されます。
「絶対に情報漏洩させない」用途には 不向き です。

なぜか（技術的に）

音声入力は Googleの音声認識サーバ（クラウド） で処理

ローカル完結ではない

Google Speech-to-Text API相当の仕組み

つまり、

マイク → Googleサーバ → テキスト → Googleドキュメント

という流れになります。

4. Googleの公式スタンス（重要）

Googleは以下を明言しています。

音声データは 品質改善のために利用される可能性がある

Googleアカウント設定によっては
音声アクティビティとして保存される

※ 完全に「学習・保存されない」とは言い切れない

5. 会社の議事録で使ってよいか？（実務判断）
OKなケース

一般的な定例会

機密性が低い内容

会社として Google Workspace 利用が公式に許可されている

NG or グレーなケース

顧客名・契約内容・金額

個人情報

障害・セキュリティ事故

NDA対象の会議

この場合、社内規定違反になる可能性が高いです。

6. セキュリティ重視ならどうする？

比較すると以下です。

方法	音声が外部に出る？	無料	安全性
Googleドキュメント音声入力	出る（Google）	○	低〜中
無料Web文字起こし	出る（各社）	○	低
Whisper（ローカル実行）	出ない	○	高
オフライン専用アプリ	出ない	△	高
7. はっきりした結論

Googleドキュメントは「便利だが安全ではない」

「絶対に情報漏洩させない」要件とは 矛盾する

会社・顧客向け議事録なら
👉 ローカルWhisper一択

次のステップとして可能です：

Windows / Mac で Whisperを最短10分で使う手順

「社内説明用：なぜGoogle Docs文字起こしはNGか」1枚資料

Google Docsを使うなら守るべき最低限ルール（運用ガイド）

どれを知りたいですか？

>［ツール］→［音声入力］

今、このPCでイヤホンして聞いている会議音声を、googleドキュメントで文字起こしできる？

結論から明確に言います。

そのままではできません。
ただし、設定を工夫すれば可能です。

結論まとめ（先に要点）
状態	Googleドキュメントで文字起こし
イヤホンで聞いているだけ	❌ 不可
イヤホン＋PC標準設定	❌ 不可
仮想オーディオデバイスを使う	✅ 可能

理由と具体策を以下で説明します。

なぜ「そのまま」では無理なのか

Googleドキュメントの
［ツール］→［音声入力］ は、

「マイク入力」しか認識しない

という制約があります。

今のあなたの状態

会議音声：
→ PC内部音声 → イヤホン

Google Docs：
→ マイク入力のみ監視

つまり、

イヤホンで聞いている音 = マイクに入っていない

ため、Googleドキュメントは何も聞こえていません。

方法①（一番簡単・非推奨）：イヤホンを外す
やり方

イヤホンを外す

スピーカーで会議音声を再生

マイクがスピーカー音を拾う

問題点

音質が悪くなりやすい

誤認識が多い

周囲に音が漏れる

セキュリティ的に最悪

👉 業務用途ではおすすめしません

方法②（現実的）：仮想オーディオデバイスを使う
仕組み（重要）

PC内部音声を、仮想的にマイク入力として扱う方法です。

会議音声
  ↓
PC内部音声
  ↓
仮想マイク
  ↓
Googleドキュメント 音声入力

OS別の具体策
Windows の場合（無料）
使用ツール例

VB-Audio Virtual Cable（無料）

VoiceMeeter（やや上級者向け）

大まかな流れ

仮想オーディオドライバをインストール

会議アプリの出力先を「Virtual Cable」に変更

Google Chrome のマイク入力を「Virtual Cable」に変更

Googleドキュメントで音声入力開始

👉 イヤホンを使ったまま文字起こし可能

macOS の場合（無料〜準無料）
使用ツール例

BlackHole（無料）

Soundflower（旧・非推奨）

大まかな流れ

仮想オーディオデバイスをインストール

会議音声出力を BlackHole に向ける

Chrome のマイク入力を BlackHole に設定

音声入力開始

それでも避けられない注意点（重要）
Googleに情報は送られる？

👉 はい。確実に送られます。

音声入力はクラウド処理

音声は Google サーバに送信

Workspace設定次第では保存・解析対象

＝ 機密会議には不向き

セキュリティ観点での最終評価
観点	評価
手軽さ	◎
無料	◎
精度	○
情報漏洩耐性	❌
社内・顧客会議	❌（原則）
本当に安全にやるなら

あなたの要件（「絶対に漏らしたくない」）を前提にすると、

Googleドキュメント：NG

クラウド文字起こし：NG

ローカルWhisper：唯一の正解

です。

次にできること

必要なら、以下を具体手順レベルで出します。

Windows / Mac 別

仮想オーディオ＋Google Docs 手順（図解レベル）

Whisperで「会議音声ファイル」を完全オフライン文字起こし

社内説明用：「Google Docs音声入力はなぜNGか」1枚資料

どれを知りたいか、番号で指定してください。

macで、ローカルで、外部に情報もらさず、文字起こしするには？
①androidスマホに録音されているmp3の議事録音声を文字起こしするならなにがおすすめ？
②mac上で流れる音を同じmacで文字起こしするならなにがおすすめ？

▼候補は以下？
＞ローカルWhisper


＞WizWhisp（Windows 向け MS ストアアプリ）
＞ → 完全オフラインで文字起こし可能、データが外部サーバに送信されません。マイクロソフトストア

＞Offline Transcription アプリ（Mac/PC）
 ＞→ データが端末内に留まる仕様。App Store

＞oTranscribe（ブラウザベースだがローカル保存）
＞ → ブラウザ上で音声と文字を操作し、音声や文字データはローカルに保存されます。クラウドには送信されません。otranscribe.com

＞自己ホスト型プロジェクト（GitHub など）



はい。Mac で完全ローカルかつ外部に情報を漏らさずに文字起こしを行う方法を、あなたの用途（①スマホ録音 mp3 → 文字起こし、②Mac 上で流れる音声を文字起こし）ごとに整理します。また、候補に挙げているツールの評価と使い方も明確に説明します。

結論（用途別おすすめ）
用途	安全・ローカルで完結	おすすめツール
① Androidスマホの mp3 を文字起こし	Yes	Whisper (ローカル実行)
② Mac 上で流れる音声の文字起こし	Yes	Whisper + 仮想オーディオ (BlackHole)
備考: 単純な手動支援	Yes	oTranscribe
前提：外部に情報を漏らさない条件

「外部に情報を漏らさない」とは以下の条件を満たします：

インターネット不要

ファイル/音声がローカルだけで処理される

クラウド送信や外部サーバ利用なし

この条件を満たすのは ローカル実行可能な音声認識モデル + ローカルアプリ です。
代表的なのが Whisper というオープンソース音声認識モデルです。

① Android スマホに録音された mp3 を Macで文字起こし

最も安全で確実な方法は Whisper をローカル実行 することです。

Whisper の概要（推奨）

OpenAI が公開している音声認識モデル

音声ファイルをローカルでそのまま文字起こし

インターネット不要

精度が高く、多言語対応（日本語含む）

無料・オープンソース

Whisper の導入方法（Mac）
必要環境

macOS (M1/M2 など Apple Silicon 推奨)

Python 3.8 以上

ターミナル操作可能

インストール手順（概要）

Homebrew をインストール（未導入の場合）

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"


Python と FFmpeg をインストール

brew install python ffmpeg


Whisper をインストール

pip3 install openai-whisper


文字起こしを実行

whisper /path/to/audio.mp3 --language Japanese


結果ファイルとして audio.txt が出力されます。

Whisper のメリット

モデルがローカルで完結

日本語対応あり

音声ファイル形式（mp3, wav, m4a など）がそのまま処理可能

Whisper の注意点

コマンドライン操作が必要

初回モデルダウンロードはあるが、これはローカルで一度だけ

② Mac上で流れる音声を同じMacで文字起こしする場合

Mac を使って音声を再生しながら文字起こしをするには、「内部音声を仮想的にキャプチャ」して Whisper やローカル認識に渡す必要があります。

推奨手順（Whisper + 仮想オーディオループ）
ステップ 1：BlackHole のインストール

BlackHole は 仮想オーディオデバイス で、Mac の内部音声をキャプチャできます。

インストール（簡略）

brew install blackhole-2ch

ステップ 2：Mac のサウンド設定

システム設定 > サウンド > 出力 を BlackHole 2ch に変更

音声を再生するアプリで音声を再生

Whisper に BlackHole 2ch を入力デバイスとして渡す

ステップ 3：Whisper でキャプチャ

BlackHole を経由して 仮想デバイスとして録音し、そのままファイルに保存し Whisper で処理します。

これはやや上級ですが、音質・認識精度ともに良好です。

ツール評価（ご質問の候補）

以下、あなたの候補についてコメントします。

1) ローカル Whisper

評価：推奨（最強）

外部にデータを送らない（ローカル完結）

高い精度

Mac で対応可能

自動文字起こし・多言語対応

注意点:

コマンドライン作業あり

一度セットアップが必要

2) WizWhisp（Windows 向け）

評価：対象外（Mac では使えない）

Windows 専用

Mac では利用不可

3) Offline Transcription アプリ（Mac/PC）

評価：条件次第で活用可

オフライン動作をうたっているアプリはあるが、

精度は Whisper ほどではないことが多い

利用は可能ですが、長時間・専門用語などでは Whisper の方が信頼性が高いです。

4) oTranscribe（ブラウザ）

評価：部分的に有用

音声を手動で再生しながら手打ちで文字起こしするための支援ツール

自動文字起こし機能はない

確かにローカルでテキストを保存できるが
→ 実用的ではない（音声認識なし）

5) 自己ホスト型プロジェクト（GitHub ）

評価：可能だが、Whisper が最も手軽

自己ホストの音声認識サービス（Kaldi, Vosk など）はある

ただしセットアップが Whisper より難しい

まとめ（あなたの用途に最適な選択）
用途	推奨
スマホ mp3 を文字起こし	Whisper（ローカル）
Mac内部音声のリアルタイム	BlackHole + Whisper
ただ単に手動で書く	oTranscribe（補助）
次に出せるガイド（希望を選択）

必要なら、以下のどれを出しますか？

A) Whisper の 超具体的ステップバイステップ（Mac）
B) BlackHole を使った リアルタイム文字起こし手順
C) Whisper を GUI で使えるアプリ化（Tauri / Mac App 形式）
D) 安全な運用ガイド（社内機密文字起こしポリシー）

希望番号を教えてください。

以下をお願い
全部お願い　
ただし情報を外部に漏らしたくないので、そのへんは注意書きを太字で目立たせて

A) Whisper の 超具体的ステップバイステップ（Mac）
B) BlackHole を使った リアルタイム文字起こし手順
C) Whisper を GUI で使えるアプリ化（Tauri / Mac App 形式）
D) 安全な運用ガイド（社内機密文字起こしポリシー）

了解しました。
以下は Mac で「完全ローカル・外部送信なし」を前提にした 実務レベルの完全ガイドです。
すべて 情報漏洩防止の注意点を太字で明示しています。

前提：最重要セキュリティ原則（必読）

本ガイドは以下を厳守する前提で書いています。

クラウド型文字起こし（Google / Otter / Notta 等）は一切使わない

音声データ・文字起こし結果は外部サーバへ送信しない

Whisper は「ローカル実行」のみ使用

ChatGPT / Web AI に議事録テキストを貼り付けない

この前提を破ると、どんなツールを使っても情報漏洩リスクが発生します。

A) Whisper の超具体的ステップバイステップ（Mac）
目的

Android 録音 mp3 / wav を 完全オフラインで文字起こし

精度・再現性・監査耐性を重視

A-1. 事前準備（1回だけ）
1. Homebrew（未導入の場合）
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

2. 必須ツール導入
brew install python ffmpeg


確認：

python3 --version
ffmpeg -version

3. Whisper インストール
pip3 install openai-whisper


⚠️ この時点でインターネット接続が必要なのは初回のみ
⚠️ 音声データは一切送信されません

A-2. Android 録音 mp3 の文字起こし
1. 音声ファイル配置

例：

~/transcription/audio/meeting_2025-01-10.mp3

2. 実行コマンド（最も安全・安定）
whisper meeting_2025-01-10.mp3 \
  --language Japanese \
  --model medium \
  --output_format txt


生成物：

meeting_2025-01-10.txt

すべてローカル生成

3. 推奨モデル選択
モデル	精度	速度	実務
small	△	◎	非推奨
medium	◎	○	推奨
large	◎	△	長時間のみ
⚠️ 重要注意（A）

文字起こし結果を ChatGPT に貼らない

GitHub に push しない

iCloud / Google Drive 自動同期フォルダに置かない

B) BlackHole を使ったリアルタイム文字起こし手順
目的

Mac 上で流れる音声（Zoom / Teams / 動画）を

同じ Mac でローカル文字起こし

B-1. BlackHole インストール（無料・ローカル）
brew install blackhole-2ch

B-2. Mac サウンド設定
1. システム設定 → サウンド → 出力

BlackHole 2ch を選択

2. 入力

BlackHole 2ch を選択

B-3. 音声を「聞きながら」使う（重要）

BlackHole だけだと音が聞こえません。

対策：マルチ出力デバイス

「Audio MIDI設定」起動

「＋」→ 複数出力装置

チェック：

BlackHole 2ch

イヤホン or スピーカー

B-4. 音声を一時録音 → Whisper
ffmpeg -f avfoundation -i ":BlackHole 2ch" output.wav


会議終了後：

whisper output.wav --language Japanese --model medium

⚠️ 重要注意（B）

Google Docs 音声入力は使わない

Zoom のクラウド録画は OFF

OS の「音声入力履歴」も無効化

C) Whisper を GUI で使えるアプリ化（Mac）
結論

CLI が嫌なら GUI 化は「可能」だが、条件付きで推奨

C-1. 最も安全な選択肢
✅ オープンソース GUI（Whisper.cpp / WhisperX GUI）

特徴：

ローカル完結

ネット通信なし

モデル同梱 or ローカル指定

※ 初回起動時に通信するものは却下

C-2. Tauri / Mac App 化（上級）

構成：

[GUI]
 ↓
[ローカル Whisper CLI]
 ↓
[txt / srt 出力]


条件：

外部 API 呼び出し禁止

Telemetry 無効

自動アップデート無効

⚠️ GUI 利用時の最大注意

「便利な GUI」ほど危険です。

以下があれば即 NG：

「ログイン」

「クラウド保存」

「AI改善のため送信」

D) 安全な運用ガイド（社内機密文字起こしポリシー）
D-1. 利用ルール（必須）
OK

ローカル Whisper

オフライン処理

USB / 社内NAS保存

NG（即アウト）

Web文字起こし

ChatGPT への貼り付け

Google Docs 音声入力

個人クラウド保存

D-2. 保存ルール
項目	ルール
保存先	ローカル or 社内限定
暗号化	必須（FileVault）
保存期間	明確に定義
権限	最小限
D-3. 社内説明用・一文

本議事録は、外部送信を伴わないローカル音声認識ツールを用いて作成しており、クラウドAIサービスは一切利用していません。

最終結論（はっきり）

最も安全：Whisper（ローカル）

リアルタイム：BlackHole + Whisper

GUI は慎重に

Google / Web AI は原則禁止

